{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dc7a6b-61a6-4755-a7d1-a81ec2d4a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: vowel-heart_dataset\\a,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav\n",
      "vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav, segment:1, label:95\n",
      "vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\A,kundan,p126,m,cycling.wav\n",
      "vowel-heart_dataset\\A,kundan,p126,m,cycling.wav, segment:1, label:126\n",
      "vowel-heart_dataset\\A,kundan,p126,m,cycling.wav, segment:2, label:126\n",
      "Processing file: vowel-heart_dataset\\A,lala,p108,m,basket ball.wav\n",
      "vowel-heart_dataset\\A,lala,p108,m,basket ball.wav, segment:1, label:108\n",
      "vowel-heart_dataset\\A,lala,p108,m,basket ball.wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\a,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\a,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\a,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\a,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\a,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\a,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\a,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\a,ravi,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,ravi,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,ravi,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\a,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\a,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\a,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\a,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav\n",
      "vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav, segment:1, label:100\n",
      "vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav, segment:2, label:100\n",
      "Processing file: vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\a103.wav\n",
      "vowel-heart_dataset\\a103.wav, segment:1, label:103\n",
      "vowel-heart_dataset\\a103.wav, segment:2, label:103\n",
      "Processing file: vowel-heart_dataset\\a113.wav\n",
      "vowel-heart_dataset\\a113.wav, segment:1, label:113\n",
      "vowel-heart_dataset\\a113.wav, segment:2, label:113\n",
      "Processing file: vowel-heart_dataset\\a88.wav\n",
      "vowel-heart_dataset\\a88.wav, segment:1, label:88\n",
      "vowel-heart_dataset\\a88.wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\a99.wav\n",
      "vowel-heart_dataset\\a99.wav, segment:1, label:99\n",
      "vowel-heart_dataset\\a99.wav, segment:2, label:99\n",
      "Processing file: vowel-heart_dataset\\Abhi,81,u,sitting.Wav\n",
      "vowel-heart_dataset\\Abhi,81,u,sitting.Wav, segment:1, label:81\n",
      "vowel-heart_dataset\\Abhi,81,u,sitting.Wav, segment:2, label:81\n",
      "Processing file: vowel-heart_dataset\\Abhi,82,a,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,82,a,sit.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Abhi,82,a,sit.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Abhi,82,e,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,82,e,sit.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Abhi,82,e,sit.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Abhi,90,o,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,90,o,sit.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Abhi,90,o,sit.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\Abhi,i,90,sitting.Wav\n",
      "vowel-heart_dataset\\Abhi,i,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Abhi,i,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\Amit,73,o,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,73,o,sitting.Wav, segment:1, label:73\n",
      "vowel-heart_dataset\\Amit,73,o,sitting.Wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\Amit,78,a,sittting.Wav\n",
      "vowel-heart_dataset\\Amit,78,a,sittting.Wav, segment:1, label:78\n",
      "vowel-heart_dataset\\Amit,78,a,sittting.Wav, segment:2, label:78\n",
      "Processing file: vowel-heart_dataset\\Amit,80,i,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,80,i,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Amit,80,i,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Amit,80,u,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,80,u,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Amit,80,u,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Amit,e,78,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,e,78,sitting.Wav, segment:1, label:78\n",
      "vowel-heart_dataset\\Amit,e,78,sitting.Wav, segment:2, label:78\n",
      "Processing file: vowel-heart_dataset\\e,abhay,76,sitting.Wav\n",
      "vowel-heart_dataset\\e,abhay,76,sitting.Wav, segment:1, label:76\n",
      "vowel-heart_dataset\\e,abhay,76,sitting.Wav, segment:2, label:76\n",
      "Processing file: vowel-heart_dataset\\e,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\e,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\e,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav\n",
      "vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\e,Piyush,108,sitting.Wav\n",
      "vowel-heart_dataset\\e,Piyush,108,sitting.Wav, segment:1, label:108\n",
      "vowel-heart_dataset\\e,Piyush,108,sitting.Wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\e,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\e,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\e,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\e,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\e,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav\n",
      "vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav, segment:1, label:65\n",
      "vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav\n",
      "vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav, segment:1, label:118\n",
      "vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav, segment:2, label:118\n",
      "Processing file: vowel-heart_dataset\\E,vhairav,p144,m,playing.wav\n",
      "vowel-heart_dataset\\E,vhairav,p144,m,playing.wav, segment:1, label:144\n",
      "vowel-heart_dataset\\E,vhairav,p144,m,playing.wav, segment:2, label:144\n",
      "Processing file: vowel-heart_dataset\\e,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\e,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\e,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\i,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav\n",
      "vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav, segment:1, label:85\n",
      "vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\i,manoj,87,sitting.Wav\n",
      "vowel-heart_dataset\\i,manoj,87,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\i,manoj,87,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav\n",
      "vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\i,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\i,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\i,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\i,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav\n",
      "vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav, segment:1, label:754\n",
      "vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav, segment:2, label:754\n",
      "Processing file: vowel-heart_dataset\\i,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\i,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\i,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav\n",
      "vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav, segment:1, label:65\n",
      "vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\I,Sanjay,p144,m,running.wav\n",
      "vowel-heart_dataset\\I,Sanjay,p144,m,running.wav, segment:1, label:144\n",
      "vowel-heart_dataset\\I,Sanjay,p144,m,running.wav, segment:2, label:144\n",
      "Processing file: vowel-heart_dataset\\i,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\i,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\i,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\Lucky,63,i,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,63,i,sitting.Wav, segment:1, label:63\n",
      "vowel-heart_dataset\\Lucky,63,i,sitting.Wav, segment:2, label:63\n",
      "Processing file: vowel-heart_dataset\\Lucky,65,e,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,65,e,sitting.Wav, segment:1, label:65\n",
      "vowel-heart_dataset\\Lucky,65,e,sitting.Wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\Lucky,65,u,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,65,u,sitting.Wav, segment:1, label:65\n",
      "vowel-heart_dataset\\Lucky,65,u,sitting.Wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\Lucky,68,o,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,68,o,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\Lucky,68,o,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\Lucky,70,a,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,70,a,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\Lucky,70,a,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\m132.wav\n",
      "vowel-heart_dataset\\m132.wav, segment:1, label:132\n",
      "vowel-heart_dataset\\m132.wav, segment:2, label:132\n",
      "Processing file: vowel-heart_dataset\\m77.wav\n",
      "vowel-heart_dataset\\m77.wav, segment:1, label:77\n",
      "vowel-heart_dataset\\m77.wav, segment:2, label:77\n",
      "Processing file: vowel-heart_dataset\\m79.wav\n",
      "vowel-heart_dataset\\m79.wav, segment:1, label:79\n",
      "vowel-heart_dataset\\m79.wav, segment:2, label:79\n",
      "Processing file: vowel-heart_dataset\\m88.wav\n",
      "vowel-heart_dataset\\m88.wav, segment:1, label:88\n",
      "vowel-heart_dataset\\m88.wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,87,a,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,87,a,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\Mohit,87,a,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,i,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,i,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,i,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,o,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,o,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,o,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,u,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,u,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,u,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,90,e,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,90,e,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Mohit,90,e,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\o,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav\n",
      "vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav, segment:1, label:75\n",
      "vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav\n",
      "vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav, segment:1, label:84\n",
      "vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav, segment:2, label:84\n",
      "Processing file: vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav\n",
      "vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav, segment:1, label:120\n",
      "vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav, segment:2, label:120\n",
      "Processing file: vowel-heart_dataset\\o,manoj,86,sitting.Wav\n",
      "vowel-heart_dataset\\o,manoj,86,sitting.Wav, segment:1, label:86\n",
      "vowel-heart_dataset\\o,manoj,86,sitting.Wav, segment:2, label:86\n",
      "Processing file: vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\o,Piyush,108,sitting.Wav\n",
      "vowel-heart_dataset\\o,Piyush,108,sitting.Wav, segment:1, label:108\n",
      "vowel-heart_dataset\\o,Piyush,108,sitting.Wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\o,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\o,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\o,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\o,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\o,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\o,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\o,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\o,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\Rashad,83,e,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,83,e,sitting.Wav, segment:1, label:83\n",
      "vowel-heart_dataset\\Rashad,83,e,sitting.Wav, segment:2, label:83\n",
      "Processing file: vowel-heart_dataset\\Rashad,85,u,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,85,u,sitting.Wav, segment:1, label:85\n",
      "vowel-heart_dataset\\Rashad,85,u,sitting.Wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\Rashad,87,i,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,87,i,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\Rashad,87,i,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\Rashad,89,o,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,89,o,sitting.Wav, segment:1, label:89\n",
      "vowel-heart_dataset\\Rashad,89,o,sitting.Wav, segment:2, label:89\n",
      "Processing file: vowel-heart_dataset\\Rashad,a,85,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,a,85,sitting.Wav, segment:1, label:85\n",
      "vowel-heart_dataset\\Rashad,a,85,sitting.Wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\Rsn,73,e,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,73,e,sitting.Wav, segment:1, label:73\n",
      "vowel-heart_dataset\\Rsn,73,e,sitting.Wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\Rsn,82,a,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,82,a,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,82,a,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,82,i,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,82,i,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,82,i,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,o,82,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,o,82,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,o,82,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,u,80,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,u,80,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Rsn,u,80,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Tanmay,105,a,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,105,a,standing.Wav, segment:1, label:105\n",
      "vowel-heart_dataset\\Tanmay,105,a,standing.Wav, segment:2, label:105\n",
      "Processing file: vowel-heart_dataset\\Tanmay,110,o,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,110,o,standing.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\Tanmay,110,o,standing.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\Tanmay,112,e,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,112,e,standing.Wav, segment:1, label:112\n",
      "vowel-heart_dataset\\Tanmay,112,e,standing.Wav, segment:2, label:112\n",
      "Processing file: vowel-heart_dataset\\Tanmay,112,i,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,112,i,standing.Wav, segment:1, label:112\n",
      "vowel-heart_dataset\\Tanmay,112,i,standing.Wav, segment:2, label:112\n",
      "Processing file: vowel-heart_dataset\\Tanmay,117,u,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,117,u,standing.Wav, segment:1, label:117\n",
      "vowel-heart_dataset\\Tanmay,117,u,standing.Wav, segment:2, label:117\n",
      "Processing file: vowel-heart_dataset\\u,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\U,Anil,p85,m,sitting.wav\n",
      "vowel-heart_dataset\\U,Anil,p85,m,sitting.wav, segment:1, label:85\n",
      "vowel-heart_dataset\\U,Anil,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav\n",
      "vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav, segment:1, label:74\n",
      "vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav, segment:2, label:74\n",
      "Processing file: vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav\n",
      "vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav, segment:1, label:122\n",
      "vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav, segment:2, label:122\n",
      "Processing file: vowel-heart_dataset\\u,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\u,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\u,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\u,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\u,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\u,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\u,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,ravi-r,98,sitting.Wav\n",
      "vowel-heart_dataset\\u,ravi-r,98,sitting.Wav, segment:1, label:98\n",
      "vowel-heart_dataset\\u,ravi-r,98,sitting.Wav, segment:2, label:98\n",
      "Processing file: vowel-heart_dataset\\U,Rubika,p86,m,walking.wav\n",
      "vowel-heart_dataset\\U,Rubika,p86,m,walking.wav, segment:1, label:86\n",
      "vowel-heart_dataset\\U,Rubika,p86,m,walking.wav, segment:2, label:86\n",
      "Processing file: vowel-heart_dataset\\u,Vibhor,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Vibhor,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Vibhor,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\v100.wav\n",
      "vowel-heart_dataset\\v100.wav, segment:1, label:100\n",
      "vowel-heart_dataset\\v100.wav, segment:2, label:100\n",
      "Processing file: vowel-heart_dataset\\v67.wav\n",
      "vowel-heart_dataset\\v67.wav, segment:1, label:67\n",
      "vowel-heart_dataset\\v67.wav, segment:2, label:67\n",
      "Processing file: vowel-heart_dataset\\v68.wav\n",
      "vowel-heart_dataset\\v68.wav, segment:1, label:68\n",
      "vowel-heart_dataset\\v68.wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\v72.wav\n",
      "vowel-heart_dataset\\v72.wav, segment:1, label:72\n",
      "vowel-heart_dataset\\v72.wav, segment:2, label:72\n",
      "Processing file: vowel-heart_dataset\\v73.wav\n",
      "vowel-heart_dataset\\v73.wav, segment:1, label:73\n",
      "vowel-heart_dataset\\v73.wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\v80.wav\n",
      "vowel-heart_dataset\\v80.wav, segment:1, label:80\n",
      "vowel-heart_dataset\\v80.wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\y105.wav\n",
      "vowel-heart_dataset\\y105.wav, segment:1, label:105\n",
      "vowel-heart_dataset\\y105.wav, segment:2, label:105\n",
      "Processing file: vowel-heart_dataset\\y90.wav\n",
      "vowel-heart_dataset\\y90.wav, segment:1, label:90\n",
      "vowel-heart_dataset\\y90.wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\y94.wav\n",
      "vowel-heart_dataset\\y94.wav, segment:1, label:94\n",
      "vowel-heart_dataset\\y94.wav, segment:2, label:94\n",
      "Processing file: vowel-heart_dataset\\y95.wav\n",
      "vowel-heart_dataset\\y95.wav, segment:1, label:95\n",
      "vowel-heart_dataset\\y95.wav, segment:2, label:95\n",
      "Extracted features shape: (230, 300, 13)\n",
      "Labels shape: (230,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 245880.7969 - mean_absolute_error: 313.0830 - val_loss: 3079.5269 - val_mean_absolute_error: 51.3258\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 9039.4648 - mean_absolute_error: 68.0624 - val_loss: 453.9644 - val_mean_absolute_error: 15.5649\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6553.5166 - mean_absolute_error: 41.2250 - val_loss: 970.1295 - val_mean_absolute_error: 23.8755\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 10168.1514 - mean_absolute_error: 44.2518 - val_loss: 1013.0070 - val_mean_absolute_error: 23.9498\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7774.6621 - mean_absolute_error: 33.1411 - val_loss: 759.3245 - val_mean_absolute_error: 20.7801\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9569.7910 - mean_absolute_error: 34.9219 - val_loss: 627.8184 - val_mean_absolute_error: 19.6995\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 7683.6030 - mean_absolute_error: 30.2081 - val_loss: 520.7125 - val_mean_absolute_error: 19.1009\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 8588.5576 - mean_absolute_error: 34.8842 - val_loss: 651.5180 - val_mean_absolute_error: 20.3018\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7764.3975 - mean_absolute_error: 32.3486 - val_loss: 782.8634 - val_mean_absolute_error: 22.5095\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6993.7451 - mean_absolute_error: 32.8308 - val_loss: 737.4076 - val_mean_absolute_error: 21.7750\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3723.5664 - mean_absolute_error: 27.4922 - val_loss: 769.6646 - val_mean_absolute_error: 22.1965\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 4523.7671 - mean_absolute_error: 30.3311 - val_loss: 569.6896 - val_mean_absolute_error: 19.1029\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2101.3367 - mean_absolute_error: 22.7069 - val_loss: 494.3289 - val_mean_absolute_error: 17.7809\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3916.7690 - mean_absolute_error: 24.4801 - val_loss: 476.0604 - val_mean_absolute_error: 17.0497\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2397.5452 - mean_absolute_error: 22.2104 - val_loss: 623.8373 - val_mean_absolute_error: 20.4255\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1687.0638 - mean_absolute_error: 20.9283 - val_loss: 585.3303 - val_mean_absolute_error: 18.6629\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1281.7256 - mean_absolute_error: 20.7915 - val_loss: 504.3521 - val_mean_absolute_error: 17.8769\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2718.6079 - mean_absolute_error: 23.7695 - val_loss: 738.3826 - val_mean_absolute_error: 21.8486\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1197.2288 - mean_absolute_error: 21.1214 - val_loss: 644.2195 - val_mean_absolute_error: 19.4988\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1419.4247 - mean_absolute_error: 24.3624 - val_loss: 774.0848 - val_mean_absolute_error: 21.0003\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 935.2671 - mean_absolute_error: 24.4233 - val_loss: 871.4572 - val_mean_absolute_error: 23.4273\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1038.5099 - mean_absolute_error: 23.5801 - val_loss: 696.2496 - val_mean_absolute_error: 20.2966\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 757.1053 - mean_absolute_error: 19.9919 - val_loss: 1071.0376 - val_mean_absolute_error: 26.8984\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 986.3320 - mean_absolute_error: 24.7103 - val_loss: 582.6936 - val_mean_absolute_error: 18.6569\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 459.6062 - mean_absolute_error: 16.8859 - val_loss: 771.6471 - val_mean_absolute_error: 21.6237\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 423.5038 - mean_absolute_error: 15.4661 - val_loss: 627.4270 - val_mean_absolute_error: 19.5341\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 302.1403 - mean_absolute_error: 13.4702 - val_loss: 549.2108 - val_mean_absolute_error: 18.4541\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 284.4570 - mean_absolute_error: 13.4869 - val_loss: 783.0903 - val_mean_absolute_error: 21.0772\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 392.2754 - mean_absolute_error: 15.3844 - val_loss: 532.5145 - val_mean_absolute_error: 17.9307\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 285.0791 - mean_absolute_error: 12.9294 - val_loss: 537.3091 - val_mean_absolute_error: 17.9275\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 190.4016 - mean_absolute_error: 10.8558 - val_loss: 517.8963 - val_mean_absolute_error: 17.5115\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 170.0346 - mean_absolute_error: 9.9747 - val_loss: 539.0433 - val_mean_absolute_error: 18.0142\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 125.4490 - mean_absolute_error: 8.7894 - val_loss: 524.9417 - val_mean_absolute_error: 18.1644\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 134.0469 - mean_absolute_error: 8.7843 - val_loss: 573.0910 - val_mean_absolute_error: 18.9193\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 179.3477 - mean_absolute_error: 10.7504 - val_loss: 496.2120 - val_mean_absolute_error: 17.8095\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 133.2755 - mean_absolute_error: 9.3319 - val_loss: 555.5253 - val_mean_absolute_error: 18.1259\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 109.9938 - mean_absolute_error: 8.5075 - val_loss: 574.3386 - val_mean_absolute_error: 18.9107\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 117.6103 - mean_absolute_error: 8.2731 - val_loss: 516.1260 - val_mean_absolute_error: 18.2416\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 97.5933 - mean_absolute_error: 7.6766 - val_loss: 527.4786 - val_mean_absolute_error: 18.4834\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 70.3314 - mean_absolute_error: 6.4941 - val_loss: 536.8079 - val_mean_absolute_error: 18.7685\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 80.7120 - mean_absolute_error: 7.0197 - val_loss: 506.3024 - val_mean_absolute_error: 18.1820\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 82.8830 - mean_absolute_error: 7.2589 - val_loss: 502.1443 - val_mean_absolute_error: 18.0780\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 71.9370 - mean_absolute_error: 6.6476 - val_loss: 517.5865 - val_mean_absolute_error: 18.2693\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 68.3309 - mean_absolute_error: 6.3969 - val_loss: 530.6446 - val_mean_absolute_error: 18.5163\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 67.2920 - mean_absolute_error: 6.3908 - val_loss: 508.6157 - val_mean_absolute_error: 18.0469\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 71.1013 - mean_absolute_error: 6.6785 - val_loss: 520.0033 - val_mean_absolute_error: 18.2955\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 58.7780 - mean_absolute_error: 6.1288 - val_loss: 530.7950 - val_mean_absolute_error: 18.3108\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 56.0748 - mean_absolute_error: 5.9055 - val_loss: 512.1632 - val_mean_absolute_error: 17.8455\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 46.3495 - mean_absolute_error: 5.3905 - val_loss: 523.4795 - val_mean_absolute_error: 17.9449\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 68.6271 - mean_absolute_error: 6.3959 - val_loss: 527.1343 - val_mean_absolute_error: 18.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 350.9630 - mean_absolute_error: 15.6156 \n",
      "Test Mean Absolute Error: 15.887894630432129\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Accuracy Percentage: 17.39%\n",
      "Actual: 72, Predicted: 100.323974609375\n",
      "Actual: 95, Predicted: 64.13053894042969\n",
      "Actual: 90, Predicted: 77.06253051757812\n",
      "Actual: 90, Predicted: 114.18009185791016\n",
      "Actual: 75, Predicted: 56.47462463378906\n",
      "Actual: 75, Predicted: 69.17396545410156\n",
      "Actual: 75, Predicted: 90.55513000488281\n",
      "Actual: 70, Predicted: 84.68574523925781\n",
      "Actual: 83, Predicted: 66.09059143066406\n",
      "Actual: 88, Predicted: 84.476806640625\n",
      "Actual: 73, Predicted: 83.86048889160156\n",
      "Actual: 95, Predicted: 86.70692443847656\n",
      "Actual: 144, Predicted: 94.46601867675781\n",
      "Actual: 110, Predicted: 95.44499206542969\n",
      "Actual: 105, Predicted: 101.25260162353516\n",
      "Actual: 120, Predicted: 100.94189453125\n",
      "Actual: 75, Predicted: 52.97322082519531\n",
      "Actual: 88, Predicted: 98.87590026855469\n",
      "Actual: 90, Predicted: 72.49526977539062\n",
      "Actual: 75, Predicted: 84.5400390625\n",
      "Actual: 68, Predicted: 67.35142517089844\n",
      "Actual: 85, Predicted: 94.9210205078125\n",
      "Actual: 86, Predicted: 97.195556640625\n",
      "Actual: 112, Predicted: 85.33540344238281\n",
      "Actual: 88, Predicted: 91.34536743164062\n",
      "Actual: 95, Predicted: 86.61769104003906\n",
      "Actual: 75, Predicted: 63.12745666503906\n",
      "Actual: 75, Predicted: 71.60063171386719\n",
      "Actual: 65, Predicted: 82.66047668457031\n",
      "Actual: 68, Predicted: 87.01991271972656\n",
      "Actual: 110, Predicted: 89.33316040039062\n",
      "Actual: 108, Predicted: 95.83123016357422\n",
      "Actual: 88, Predicted: 73.07109069824219\n",
      "Actual: 73, Predicted: 92.02897644042969\n",
      "Actual: 70, Predicted: 47.298118591308594\n",
      "Actual: 88, Predicted: 105.78872680664062\n",
      "Actual: 87, Predicted: 133.21116638183594\n",
      "Actual: 88, Predicted: 77.26889038085938\n",
      "Actual: 87, Predicted: 86.78134155273438\n",
      "Actual: 75, Predicted: 78.19680786132812\n",
      "Actual: 95, Predicted: 81.9422607421875\n",
      "Actual: 82, Predicted: 105.13658142089844\n",
      "Actual: 108, Predicted: 103.46316528320312\n",
      "Actual: 144, Predicted: 107.43141174316406\n",
      "Actual: 132, Predicted: 105.80809020996094\n",
      "Actual: 132, Predicted: 121.73149108886719\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "num_segments = 2  # Number of segments to divide each audio file\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "\n",
    "# Directory containing audio files\n",
    "input_dir = 'vowel-heart_dataset'  # Replace with your directory containing .wav files\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Function to extract MFCC features from an audio file segment\n",
    "def extract_mfcc_segment(signal, sample_rate, start, finish):\n",
    "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "# Function to extract oximeter reading from file name\n",
    "def extract_oximeter_reading(file_name):\n",
    "    oximeter_reading = int(''.join(filter(str.isdigit, file_name)))\n",
    "    return oximeter_reading\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "def pad_or_truncate(mfcc, max_length):\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "# Process each file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\") or filename.endswith(\".Wav\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Load audio file\n",
    "        audio, original_fs = sf.read(file_path)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio.T)\n",
    "        if original_fs != fs:\n",
    "            audio = librosa.resample(audio, orig_sr=original_fs, target_sr=fs)\n",
    "        \n",
    "        # Calculate segment length and number of MFCC vectors per segment\n",
    "        samples_per_segment = int(len(audio) / num_segments)\n",
    "        num_mfcc_vectors_per_segment = int(np.ceil(samples_per_segment / hop_length))\n",
    "\n",
    "        # Extract MFCC features from each segment\n",
    "        for segment in range(num_segments):\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            \n",
    "            mfcc_features = extract_mfcc_segment(audio, fs, start, finish)\n",
    "            mfcc_features = pad_or_truncate(mfcc_features, max_length)\n",
    "            \n",
    "            # Append the MFCC features of the current segment\n",
    "            features.append(mfcc_features)\n",
    "            # Append the label (oximeter reading) of the current segment\n",
    "            oximeter_reading = extract_oximeter_reading(filename)\n",
    "            labels.append(oximeter_reading)\n",
    "            print(f\"{file_path}, segment:{segment + 1}, label:{oximeter_reading}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(max_length, n_mfcc)),\n",
    "    Dense(256, activation='relu'),\n",
    "   # Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'trained_model.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Load the model (you can load it in a different script or session)\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy percentage\n",
    "tolerance = 5  # Define a tolerance level for the predictions\n",
    "accurate_predictions = np.sum(np.abs(y_pred.flatten() - y_test) <= tolerance)\n",
    "accuracy_percentage = (accurate_predictions / len(y_test)) * 100\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n",
    "\n",
    "# Print the predictions and actual labels\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_pred[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e62f9fa-60c7-41a2-a03f-7641606fe28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "Recording...\n",
      "Recording finished\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "Predicted Value: 151.00010681152344\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import sounddevice as sd\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "record_duration = 6  # Duration of the recording in seconds\n",
    "\n",
    "# Load the trained model\n",
    "model_save_path = 'trained_model.h5'\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Record audio for the specified duration\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(record_duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished\")\n",
    "\n",
    "# Convert to mono if needed\n",
    "if audio.ndim > 1:\n",
    "    audio = librosa.to_mono(audio.T)\n",
    "\n",
    "# Extract MFCC features from the recorded audio\n",
    "def extract_mfcc_from_audio(audio, sample_rate, n_mfcc, n_fft, hop_length, max_length):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc = mfcc.T\n",
    "    # Pad or truncate MFCC features to a consistent length\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return  mfcc\n",
    "\n",
    "mfcc_features = extract_mfcc_from_audio(audio.flatten(), fs, n_mfcc, n_fft, hop_length, max_length)\n",
    "mfcc_features = np.expand_dims(mfcc_features, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict the output using the model\n",
    "prediction = model.predict(mfcc_features)\n",
    "print(f\"Predicted Value: {prediction[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b68a25c-8609-445f-82e0-cc40c6e9a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: vowel-heart_dataset\\a,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav\n",
      "vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav, segment:1, label:95\n",
      "vowel-heart_dataset\\A,Gokul,p95,m,sitting.wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\A,kundan,p126,m,cycling.wav\n",
      "vowel-heart_dataset\\A,kundan,p126,m,cycling.wav, segment:1, label:126\n",
      "vowel-heart_dataset\\A,kundan,p126,m,cycling.wav, segment:2, label:126\n",
      "Processing file: vowel-heart_dataset\\A,lala,p108,m,basket ball.wav\n",
      "vowel-heart_dataset\\A,lala,p108,m,basket ball.wav, segment:1, label:108\n",
      "vowel-heart_dataset\\A,lala,p108,m,basket ball.wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\a,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\a,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\a,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\a,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\a,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\a,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\a,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\a,ravi,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,ravi,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,ravi,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\a,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\a,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\a,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\a,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\a,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\a,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav\n",
      "vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav, segment:1, label:100\n",
      "vowel-heart_dataset\\A,Vishwanath,p100,m,sitting.wav, segment:2, label:100\n",
      "Processing file: vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\a,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\a103.wav\n",
      "vowel-heart_dataset\\a103.wav, segment:1, label:103\n",
      "vowel-heart_dataset\\a103.wav, segment:2, label:103\n",
      "Processing file: vowel-heart_dataset\\a113.wav\n",
      "vowel-heart_dataset\\a113.wav, segment:1, label:113\n",
      "vowel-heart_dataset\\a113.wav, segment:2, label:113\n",
      "Processing file: vowel-heart_dataset\\a88.wav\n",
      "vowel-heart_dataset\\a88.wav, segment:1, label:88\n",
      "vowel-heart_dataset\\a88.wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\a99.wav\n",
      "vowel-heart_dataset\\a99.wav, segment:1, label:99\n",
      "vowel-heart_dataset\\a99.wav, segment:2, label:99\n",
      "Processing file: vowel-heart_dataset\\Abhi,81,u,sitting.Wav\n",
      "vowel-heart_dataset\\Abhi,81,u,sitting.Wav, segment:1, label:81\n",
      "vowel-heart_dataset\\Abhi,81,u,sitting.Wav, segment:2, label:81\n",
      "Processing file: vowel-heart_dataset\\Abhi,82,a,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,82,a,sit.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Abhi,82,a,sit.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Abhi,82,e,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,82,e,sit.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Abhi,82,e,sit.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Abhi,90,o,sit.Wav\n",
      "vowel-heart_dataset\\Abhi,90,o,sit.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Abhi,90,o,sit.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\Abhi,i,90,sitting.Wav\n",
      "vowel-heart_dataset\\Abhi,i,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Abhi,i,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\Amit,73,o,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,73,o,sitting.Wav, segment:1, label:73\n",
      "vowel-heart_dataset\\Amit,73,o,sitting.Wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\Amit,78,a,sittting.Wav\n",
      "vowel-heart_dataset\\Amit,78,a,sittting.Wav, segment:1, label:78\n",
      "vowel-heart_dataset\\Amit,78,a,sittting.Wav, segment:2, label:78\n",
      "Processing file: vowel-heart_dataset\\Amit,80,i,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,80,i,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Amit,80,i,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Amit,80,u,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,80,u,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Amit,80,u,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Amit,e,78,sitting.Wav\n",
      "vowel-heart_dataset\\Amit,e,78,sitting.Wav, segment:1, label:78\n",
      "vowel-heart_dataset\\Amit,e,78,sitting.Wav, segment:2, label:78\n",
      "Processing file: vowel-heart_dataset\\e,abhay,76,sitting.Wav\n",
      "vowel-heart_dataset\\e,abhay,76,sitting.Wav, segment:1, label:76\n",
      "vowel-heart_dataset\\e,abhay,76,sitting.Wav, segment:2, label:76\n",
      "Processing file: vowel-heart_dataset\\e,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\e,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\e,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav\n",
      "vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\e,Mithilesh,68,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\e,Piyush,108,sitting.Wav\n",
      "vowel-heart_dataset\\e,Piyush,108,sitting.Wav, segment:1, label:108\n",
      "vowel-heart_dataset\\e,Piyush,108,sitting.Wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\e,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\e,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\e,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\e,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\e,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav\n",
      "vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav, segment:1, label:65\n",
      "vowel-heart_dataset\\E,Saurav,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav\n",
      "vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav, segment:1, label:118\n",
      "vowel-heart_dataset\\E,Shaurya,p118,m,sitting.wav, segment:2, label:118\n",
      "Processing file: vowel-heart_dataset\\E,vhairav,p144,m,playing.wav\n",
      "vowel-heart_dataset\\E,vhairav,p144,m,playing.wav, segment:1, label:144\n",
      "vowel-heart_dataset\\E,vhairav,p144,m,playing.wav, segment:2, label:144\n",
      "Processing file: vowel-heart_dataset\\e,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\e,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\e,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\e,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\i,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav\n",
      "vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav, segment:1, label:85\n",
      "vowel-heart_dataset\\I,Kishlay,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\i,manoj,87,sitting.Wav\n",
      "vowel-heart_dataset\\i,manoj,87,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\i,manoj,87,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav\n",
      "vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\i,Mithilesh,68,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\i,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\i,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\i,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\i,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav\n",
      "vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav, segment:1, label:754\n",
      "vowel-heart_dataset\\i,ravi,75,sitting.m4a.Wav, segment:2, label:754\n",
      "Processing file: vowel-heart_dataset\\i,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\i,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\i,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav\n",
      "vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav, segment:1, label:65\n",
      "vowel-heart_dataset\\I,Sagar,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\I,Sanjay,p144,m,running.wav\n",
      "vowel-heart_dataset\\I,Sanjay,p144,m,running.wav, segment:1, label:144\n",
      "vowel-heart_dataset\\I,Sanjay,p144,m,running.wav, segment:2, label:144\n",
      "Processing file: vowel-heart_dataset\\i,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\i,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\i,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\i,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\Lucky,63,i,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,63,i,sitting.Wav, segment:1, label:63\n",
      "vowel-heart_dataset\\Lucky,63,i,sitting.Wav, segment:2, label:63\n",
      "Processing file: vowel-heart_dataset\\Lucky,65,e,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,65,e,sitting.Wav, segment:1, label:65\n",
      "vowel-heart_dataset\\Lucky,65,e,sitting.Wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\Lucky,65,u,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,65,u,sitting.Wav, segment:1, label:65\n",
      "vowel-heart_dataset\\Lucky,65,u,sitting.Wav, segment:2, label:65\n",
      "Processing file: vowel-heart_dataset\\Lucky,68,o,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,68,o,sitting.Wav, segment:1, label:68\n",
      "vowel-heart_dataset\\Lucky,68,o,sitting.Wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\Lucky,70,a,sitting.Wav\n",
      "vowel-heart_dataset\\Lucky,70,a,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\Lucky,70,a,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\m132.wav\n",
      "vowel-heart_dataset\\m132.wav, segment:1, label:132\n",
      "vowel-heart_dataset\\m132.wav, segment:2, label:132\n",
      "Processing file: vowel-heart_dataset\\m77.wav\n",
      "vowel-heart_dataset\\m77.wav, segment:1, label:77\n",
      "vowel-heart_dataset\\m77.wav, segment:2, label:77\n",
      "Processing file: vowel-heart_dataset\\m79.wav\n",
      "vowel-heart_dataset\\m79.wav, segment:1, label:79\n",
      "vowel-heart_dataset\\m79.wav, segment:2, label:79\n",
      "Processing file: vowel-heart_dataset\\m88.wav\n",
      "vowel-heart_dataset\\m88.wav, segment:1, label:88\n",
      "vowel-heart_dataset\\m88.wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,87,a,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,87,a,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\Mohit,87,a,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,i,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,i,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,i,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,o,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,o,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,o,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,88,u,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,88,u,sitting.Wav, segment:1, label:88\n",
      "vowel-heart_dataset\\Mohit,88,u,sitting.Wav, segment:2, label:88\n",
      "Processing file: vowel-heart_dataset\\Mohit,90,e,sitting.Wav\n",
      "vowel-heart_dataset\\Mohit,90,e,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\Mohit,90,e,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\o,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav\n",
      "vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav, segment:1, label:75\n",
      "vowel-heart_dataset\\O,Abhimanyu,p75,m,sitting.wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav\n",
      "vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav, segment:1, label:84\n",
      "vowel-heart_dataset\\O,Ayush,p84,m,sitting.wav, segment:2, label:84\n",
      "Processing file: vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav\n",
      "vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav, segment:1, label:120\n",
      "vowel-heart_dataset\\O,Kitasha,p120,m,playing.wav, segment:2, label:120\n",
      "Processing file: vowel-heart_dataset\\o,manoj,86,sitting.Wav\n",
      "vowel-heart_dataset\\o,manoj,86,sitting.Wav, segment:1, label:86\n",
      "vowel-heart_dataset\\o,manoj,86,sitting.Wav, segment:2, label:86\n",
      "Processing file: vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\o,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\o,Piyush,108,sitting.Wav\n",
      "vowel-heart_dataset\\o,Piyush,108,sitting.Wav, segment:1, label:108\n",
      "vowel-heart_dataset\\o,Piyush,108,sitting.Wav, segment:2, label:108\n",
      "Processing file: vowel-heart_dataset\\o,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\o,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\o,ravi-r,95,sitting.Wav\n",
      "vowel-heart_dataset\\o,ravi-r,95,sitting.Wav, segment:1, label:95\n",
      "vowel-heart_dataset\\o,ravi-r,95,sitting.Wav, segment:2, label:95\n",
      "Processing file: vowel-heart_dataset\\o,Vibhor,70,sitting.Wav\n",
      "vowel-heart_dataset\\o,Vibhor,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\o,Vibhor,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\o,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\Rashad,83,e,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,83,e,sitting.Wav, segment:1, label:83\n",
      "vowel-heart_dataset\\Rashad,83,e,sitting.Wav, segment:2, label:83\n",
      "Processing file: vowel-heart_dataset\\Rashad,85,u,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,85,u,sitting.Wav, segment:1, label:85\n",
      "vowel-heart_dataset\\Rashad,85,u,sitting.Wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\Rashad,87,i,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,87,i,sitting.Wav, segment:1, label:87\n",
      "vowel-heart_dataset\\Rashad,87,i,sitting.Wav, segment:2, label:87\n",
      "Processing file: vowel-heart_dataset\\Rashad,89,o,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,89,o,sitting.Wav, segment:1, label:89\n",
      "vowel-heart_dataset\\Rashad,89,o,sitting.Wav, segment:2, label:89\n",
      "Processing file: vowel-heart_dataset\\Rashad,a,85,sitting.Wav\n",
      "vowel-heart_dataset\\Rashad,a,85,sitting.Wav, segment:1, label:85\n",
      "vowel-heart_dataset\\Rashad,a,85,sitting.Wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\Rsn,73,e,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,73,e,sitting.Wav, segment:1, label:73\n",
      "vowel-heart_dataset\\Rsn,73,e,sitting.Wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\Rsn,82,a,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,82,a,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,82,a,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,82,i,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,82,i,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,82,i,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,o,82,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,o,82,sitting.Wav, segment:1, label:82\n",
      "vowel-heart_dataset\\Rsn,o,82,sitting.Wav, segment:2, label:82\n",
      "Processing file: vowel-heart_dataset\\Rsn,u,80,sitting.Wav\n",
      "vowel-heart_dataset\\Rsn,u,80,sitting.Wav, segment:1, label:80\n",
      "vowel-heart_dataset\\Rsn,u,80,sitting.Wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\Tanmay,105,a,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,105,a,standing.Wav, segment:1, label:105\n",
      "vowel-heart_dataset\\Tanmay,105,a,standing.Wav, segment:2, label:105\n",
      "Processing file: vowel-heart_dataset\\Tanmay,110,o,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,110,o,standing.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\Tanmay,110,o,standing.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\Tanmay,112,e,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,112,e,standing.Wav, segment:1, label:112\n",
      "vowel-heart_dataset\\Tanmay,112,e,standing.Wav, segment:2, label:112\n",
      "Processing file: vowel-heart_dataset\\Tanmay,112,i,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,112,i,standing.Wav, segment:1, label:112\n",
      "vowel-heart_dataset\\Tanmay,112,i,standing.Wav, segment:2, label:112\n",
      "Processing file: vowel-heart_dataset\\Tanmay,117,u,standing.Wav\n",
      "vowel-heart_dataset\\Tanmay,117,u,standing.Wav, segment:1, label:117\n",
      "vowel-heart_dataset\\Tanmay,117,u,standing.Wav, segment:2, label:117\n",
      "Processing file: vowel-heart_dataset\\u,abhay,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,abhay,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,abhay,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\U,Anil,p85,m,sitting.wav\n",
      "vowel-heart_dataset\\U,Anil,p85,m,sitting.wav, segment:1, label:85\n",
      "vowel-heart_dataset\\U,Anil,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav\n",
      "vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav, segment:1, label:74\n",
      "vowel-heart_dataset\\U,Anjana,p74,m,sitting.wav, segment:2, label:74\n",
      "Processing file: vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav\n",
      "vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav, segment:1, label:122\n",
      "vowel-heart_dataset\\U,Gayatri,p122,m,playing.wav, segment:2, label:122\n",
      "Processing file: vowel-heart_dataset\\u,manoj,90,sitting.Wav\n",
      "vowel-heart_dataset\\u,manoj,90,sitting.Wav, segment:1, label:90\n",
      "vowel-heart_dataset\\u,manoj,90,sitting.Wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav\n",
      "vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav, segment:1, label:70\n",
      "vowel-heart_dataset\\u,Mithilesh,70,sitting.Wav, segment:2, label:70\n",
      "Processing file: vowel-heart_dataset\\u,Piyush,110,sitting.Wav\n",
      "vowel-heart_dataset\\u,Piyush,110,sitting.Wav, segment:1, label:110\n",
      "vowel-heart_dataset\\u,Piyush,110,sitting.Wav, segment:2, label:110\n",
      "Processing file: vowel-heart_dataset\\u,Rajat,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Rajat,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Rajat,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,ravi,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,ravi,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,ravi,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,ravi-r,98,sitting.Wav\n",
      "vowel-heart_dataset\\u,ravi-r,98,sitting.Wav, segment:1, label:98\n",
      "vowel-heart_dataset\\u,ravi-r,98,sitting.Wav, segment:2, label:98\n",
      "Processing file: vowel-heart_dataset\\U,Rubika,p86,m,walking.wav\n",
      "vowel-heart_dataset\\U,Rubika,p86,m,walking.wav, segment:1, label:86\n",
      "vowel-heart_dataset\\U,Rubika,p86,m,walking.wav, segment:2, label:86\n",
      "Processing file: vowel-heart_dataset\\u,Vibhor,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Vibhor,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Vibhor,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav\n",
      "vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav, segment:1, label:75\n",
      "vowel-heart_dataset\\u,Yuvraj,75,sitting.Wav, segment:2, label:75\n",
      "Processing file: vowel-heart_dataset\\v100.wav\n",
      "vowel-heart_dataset\\v100.wav, segment:1, label:100\n",
      "vowel-heart_dataset\\v100.wav, segment:2, label:100\n",
      "Processing file: vowel-heart_dataset\\v67.wav\n",
      "vowel-heart_dataset\\v67.wav, segment:1, label:67\n",
      "vowel-heart_dataset\\v67.wav, segment:2, label:67\n",
      "Processing file: vowel-heart_dataset\\v68.wav\n",
      "vowel-heart_dataset\\v68.wav, segment:1, label:68\n",
      "vowel-heart_dataset\\v68.wav, segment:2, label:68\n",
      "Processing file: vowel-heart_dataset\\v72.wav\n",
      "vowel-heart_dataset\\v72.wav, segment:1, label:72\n",
      "vowel-heart_dataset\\v72.wav, segment:2, label:72\n",
      "Processing file: vowel-heart_dataset\\v73.wav\n",
      "vowel-heart_dataset\\v73.wav, segment:1, label:73\n",
      "vowel-heart_dataset\\v73.wav, segment:2, label:73\n",
      "Processing file: vowel-heart_dataset\\v80.wav\n",
      "vowel-heart_dataset\\v80.wav, segment:1, label:80\n",
      "vowel-heart_dataset\\v80.wav, segment:2, label:80\n",
      "Processing file: vowel-heart_dataset\\y105.wav\n",
      "vowel-heart_dataset\\y105.wav, segment:1, label:105\n",
      "vowel-heart_dataset\\y105.wav, segment:2, label:105\n",
      "Processing file: vowel-heart_dataset\\y90.wav\n",
      "vowel-heart_dataset\\y90.wav, segment:1, label:90\n",
      "vowel-heart_dataset\\y90.wav, segment:2, label:90\n",
      "Processing file: vowel-heart_dataset\\y94.wav\n",
      "vowel-heart_dataset\\y94.wav, segment:1, label:94\n",
      "vowel-heart_dataset\\y94.wav, segment:2, label:94\n",
      "Processing file: vowel-heart_dataset\\y95.wav\n",
      "vowel-heart_dataset\\y95.wav, segment:1, label:95\n",
      "vowel-heart_dataset\\y95.wav, segment:2, label:95\n",
      "Extracted features shape: (230, 300, 13)\n",
      "Labels shape: (230,)\n",
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 92446.1562 - mean_absolute_error: 194.0790\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7693.4429 - mean_absolute_error: 71.7000  \n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4131.4048 - mean_absolute_error: 37.1594\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6545.1362 - mean_absolute_error: 41.9578  \n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5377.6865 - mean_absolute_error: 36.1145 \n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3016.8416 - mean_absolute_error: 31.3162\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2749.7578 - mean_absolute_error: 27.0662 \n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1842.0432 - mean_absolute_error: 25.3166 \n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1074.5266 - mean_absolute_error: 21.7791 \n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1240.7800 - mean_absolute_error: 21.5623 \n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 596.5340 - mean_absolute_error: 17.2848 \n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 547.7903 - mean_absolute_error: 17.6828 \n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 427.1424 - mean_absolute_error: 16.7912 \n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 429.2715 - mean_absolute_error: 16.4365 \n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 401.4958 - mean_absolute_error: 16.6491 \n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 308.3354 - mean_absolute_error: 14.3850 \n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 248.7978 - mean_absolute_error: 12.4374 \n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 186.1261 - mean_absolute_error: 10.4992 \n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 230.4133 - mean_absolute_error: 12.0034 \n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 203.4532 - mean_absolute_error: 11.5520 \n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 206.0298 - mean_absolute_error: 11.3248 \n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 188.7053 - mean_absolute_error: 10.8037 \n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 178.3067 - mean_absolute_error: 10.3469 \n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 186.4073 - mean_absolute_error: 10.5312 \n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 155.4039 - mean_absolute_error: 9.6619 \n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 165.9561 - mean_absolute_error: 9.8511  \n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 137.1449 - mean_absolute_error: 9.0323 \n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 114.0215 - mean_absolute_error: 8.0907\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 120.9597 - mean_absolute_error: 8.3956 \n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 124.8803 - mean_absolute_error: 9.0347\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 151.9745 - mean_absolute_error: 9.6926 \n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 153.5375 - mean_absolute_error: 9.7392 \n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 120.1230 - mean_absolute_error: 8.7926\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 152.3247 - mean_absolute_error: 9.7989 \n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 188.1264 - mean_absolute_error: 10.9090 \n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 154.6038 - mean_absolute_error: 9.9325 \n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 118.2661 - mean_absolute_error: 8.1631 \n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 139.1949 - mean_absolute_error: 9.6125 \n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 92.0443 - mean_absolute_error: 7.7152 \n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 83.6296 - mean_absolute_error: 7.1469 \n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 80.6430 - mean_absolute_error: 7.0331 \n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 85.7528 - mean_absolute_error: 6.9449 \n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 78.0020 - mean_absolute_error: 7.0292  \n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 74.0479 - mean_absolute_error: 6.5102\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 60.5843 - mean_absolute_error: 5.7726 \n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 79.3777 - mean_absolute_error: 6.9615 \n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 65.0021 - mean_absolute_error: 6.0593 \n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 50.3989 - mean_absolute_error: 5.1975 \n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 49.9154 - mean_absolute_error: 5.4340 \n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 46.9353 - mean_absolute_error: 5.2525 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 298.0335 - mean_absolute_error: 12.9088  \n",
      "Test Mean Absolute Error: 13.204462051391602\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "Accuracy Percentage: 86.11%\n",
      "Actual: 72, Predicted: 86.59745025634766\n",
      "Actual: 95, Predicted: 57.952415466308594\n",
      "Actual: 90, Predicted: 80.2306137084961\n",
      "Actual: 90, Predicted: 108.23477935791016\n",
      "Actual: 75, Predicted: 76.9393539428711\n",
      "Actual: 75, Predicted: 81.4524154663086\n",
      "Actual: 75, Predicted: 85.18372344970703\n",
      "Actual: 70, Predicted: 74.2496566772461\n",
      "Actual: 83, Predicted: 72.53765106201172\n",
      "Actual: 88, Predicted: 101.07548522949219\n",
      "Actual: 73, Predicted: 77.2585678100586\n",
      "Actual: 95, Predicted: 88.9222412109375\n",
      "Actual: 144, Predicted: 84.13593292236328\n",
      "Actual: 110, Predicted: 106.82762908935547\n",
      "Actual: 105, Predicted: 110.1688461303711\n",
      "Actual: 120, Predicted: 104.68197631835938\n",
      "Actual: 75, Predicted: 71.48348236083984\n",
      "Actual: 88, Predicted: 68.21300506591797\n",
      "Actual: 90, Predicted: 79.81855010986328\n",
      "Actual: 75, Predicted: 87.90412902832031\n",
      "Actual: 68, Predicted: 77.25890350341797\n",
      "Actual: 85, Predicted: 93.13301086425781\n",
      "Actual: 86, Predicted: 95.41626739501953\n",
      "Actual: 112, Predicted: 90.78136444091797\n",
      "Actual: 88, Predicted: 90.54094696044922\n",
      "Actual: 95, Predicted: 84.14659118652344\n",
      "Actual: 75, Predicted: 74.60698699951172\n",
      "Actual: 75, Predicted: 66.28101348876953\n",
      "Actual: 65, Predicted: 88.43047332763672\n",
      "Actual: 68, Predicted: 63.685882568359375\n",
      "Actual: 110, Predicted: 89.73207092285156\n",
      "Actual: 108, Predicted: 98.6429672241211\n",
      "Actual: 88, Predicted: 75.98131561279297\n",
      "Actual: 73, Predicted: 99.74332427978516\n",
      "Actual: 70, Predicted: 58.515953063964844\n",
      "Actual: 88, Predicted: 91.50147247314453\n",
      "Actual: 87, Predicted: 106.92816925048828\n",
      "Actual: 88, Predicted: 77.45960235595703\n",
      "Actual: 87, Predicted: 92.70708465576172\n",
      "Actual: 75, Predicted: 81.71405792236328\n",
      "Actual: 95, Predicted: 90.49961853027344\n",
      "Actual: 82, Predicted: 78.58617401123047\n",
      "Actual: 108, Predicted: 98.90656280517578\n",
      "Actual: 144, Predicted: 103.54297637939453\n",
      "Actual: 132, Predicted: 101.60762786865234\n",
      "Actual: 132, Predicted: 103.25261688232422\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "num_segments = 2  # Number of segments to divide each audio file\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "\n",
    "# Directory containing audio files\n",
    "input_dir = 'vowel-heart_dataset'  # Replace with your directory containing .wav files\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Function to extract MFCC features from an audio file segment\n",
    "def extract_mfcc_segment(signal, sample_rate, start, finish):\n",
    "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "# Function to extract oximeter reading from file name\n",
    "def extract_oximeter_reading(file_name):\n",
    "    oximeter_reading = int(''.join(filter(str.isdigit, file_name)))\n",
    "    return oximeter_reading\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "def pad_or_truncate(mfcc, max_length):\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "# Process each file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\") or filename.endswith(\".Wav\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Load audio file\n",
    "        audio, original_fs = sf.read(file_path)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio.T)\n",
    "        if original_fs != fs:\n",
    "            audio = librosa.resample(audio, orig_sr=original_fs, target_sr=fs)\n",
    "        \n",
    "        # Calculate segment length and number of MFCC vectors per segment\n",
    "        samples_per_segment = int(len(audio) / num_segments)\n",
    "        num_mfcc_vectors_per_segment = int(np.ceil(samples_per_segment / hop_length))\n",
    "\n",
    "        # Extract MFCC features from each segment\n",
    "        for segment in range(num_segments):\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            \n",
    "            mfcc_features = extract_mfcc_segment(audio, fs, start, finish)\n",
    "            mfcc_features = pad_or_truncate(mfcc_features, max_length)\n",
    "            \n",
    "            # Append the MFCC features of the current segment\n",
    "            features.append(mfcc_features)\n",
    "            # Append the label (oximeter reading) of the current segment\n",
    "            oximeter_reading = extract_oximeter_reading(filename)\n",
    "            labels.append(oximeter_reading)\n",
    "            print(f\"{file_path}, segment:{segment + 1}, label:{oximeter_reading}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(max_length, n_mfcc)),\n",
    "    Dense(256, activation='relu'),\n",
    "    # Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'trained_model.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Load the model (you can load it in a different script or session)\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Predict the labels\n",
    "#print(len(X_test))\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean percentage error\n",
    "percentage_errors = np.abs((y_test - y_pred.flatten()) / y_test) * 100\n",
    "mean_percentage_error = np.mean(percentage_errors)\n",
    "\n",
    "# Calculate the accuracy percentage\n",
    "accuracy_percentage = 100 - mean_percentage_error\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n",
    "\n",
    "# Print the predictions and actual labels\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_pred[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecbf35f-e5a5-47ad-b0fc-2f0c676c9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "Recording audio...\n",
      "Recording complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Estimated Heart Rate (bpm): 75.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "num_segments = 2  # Number of segments to divide each audio file\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "model_save_path = 'trained_model.h5'  # Path to the trained model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Function to extract MFCC features from an audio file segment\n",
    "def extract_mfcc_segment(signal, sample_rate, start, finish):\n",
    "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "def pad_or_truncate(mfcc, max_length):\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio(duration=5, sample_rate=fs):\n",
    "    print(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()\n",
    "    print(\"Recording complete.\")\n",
    "    return audio_data.flatten(), sample_rate\n",
    "\n",
    "# Function to process audio and predict heart rate\n",
    "def predict_heart_rate(audio_data, sample_rate):\n",
    "    # Calculate segment length and number of MFCC vectors per segment\n",
    "    samples_per_segment = int(len(audio_data) / num_segments)\n",
    "    num_mfcc_vectors_per_segment = int(np.ceil(samples_per_segment / hop_length))\n",
    "\n",
    "    all_mfcc_features = []\n",
    "    \n",
    "    # Extract MFCC features from each segment\n",
    "    for segment in range(num_segments):\n",
    "        start = samples_per_segment * segment\n",
    "        finish = start + samples_per_segment\n",
    "\n",
    "        mfcc_features = extract_mfcc_segment(audio_data, sample_rate, start, finish)\n",
    "        mfcc_features = pad_or_truncate(mfcc_features, max_length)\n",
    "        \n",
    "        all_mfcc_features.append(mfcc_features)\n",
    "    \n",
    "    all_mfcc_features = np.array(all_mfcc_features)\n",
    "\n",
    "    # Predict heart rate\n",
    "    predictions = model.predict(all_mfcc_features)\n",
    "    avg_prediction = np.mean(predictions)\n",
    "    \n",
    "    return avg_prediction\n",
    "\n",
    "# Record audio for 5 seconds and predict heart rate\n",
    "recorded_audio_data, recorded_sample_rate = record_audio(duration=5)\n",
    "estimated_heart_rate = predict_heart_rate(recorded_audio_data, recorded_sample_rate)\n",
    "\n",
    "print(f\"Estimated Heart Rate (bpm): {estimated_heart_rate:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e6b9e-a4e7-4ca9-b049-607a910cb271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
