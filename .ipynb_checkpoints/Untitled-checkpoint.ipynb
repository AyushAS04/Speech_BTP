{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb5110-691d-4817-a837-aae1e8bff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "num_segments = 2  # Number of segments to divide each audio file\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "\n",
    "# Directory containing audio files\n",
    "input_dir = 'wav files'  # Replace with your directory containing .wav files\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Function to extract MFCC features from an audio file segment\n",
    "def extract_mfcc_segment(signal, sample_rate, start, finish):\n",
    "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "# Function to extract oximeter reading from file name\n",
    "def extract_oximeter_reading(file_name):\n",
    "    oximeter_reading = int(''.join(filter(str.isdigit, file_name)))\n",
    "    return oximeter_reading\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "def pad_or_truncate(mfcc, max_length):\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "# Process each file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Load audio file\n",
    "        audio, original_fs = sf.read(file_path)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio.T)\n",
    "        if original_fs != fs:\n",
    "            audio = librosa.resample(audio, orig_sr=original_fs, target_sr=fs)\n",
    "        \n",
    "        # Calculate segment length and number of MFCC vectors per segment\n",
    "        samples_per_segment = int(len(audio) / num_segments)\n",
    "        num_mfcc_vectors_per_segment = int(np.ceil(samples_per_segment / hop_length))\n",
    "\n",
    "        # Extract MFCC features from each segment\n",
    "        for segment in range(num_segments):\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            \n",
    "            mfcc_features = extract_mfcc_segment(audio, fs, start, finish)\n",
    "            mfcc_features = pad_or_truncate(mfcc_features, max_length)\n",
    "            \n",
    "            # Append the MFCC features of the current segment\n",
    "            features.append(mfcc_features)\n",
    "            # Append the label (oximeter reading) of the current segment\n",
    "            oximeter_reading = extract_oximeter_reading(filename)\n",
    "            labels.append(oximeter_reading)\n",
    "            print(f\"{file_path}, segment:{segment + 1}, label:{oximeter_reading}\")\n",
    "            print(features)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81878c8-2d4b-4e71-bcdb-4116c4028aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e64115f-9e44-464f-9c4a-f5be9556dcb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Assuming the features and labels are already defined in your previous code\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mplot_mfcc_label_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mplot_mfcc_label_correlation\u001b[1;34m(features, labels)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_mfcc_label_correlation\u001b[39m(features, labels):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Aggregate MFCC features by taking the mean across the frames (axis=1)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     mean_mfcc_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from the mean MFCC features and labels\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(mean_mfcc_features, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMFCC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mean_mfcc_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:106\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    102\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    108\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:77\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[1;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[0;32m     75\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[1;32m---> 77\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     78\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(items)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_mfcc_label_correlation(features, labels):\n",
    "    # Aggregate MFCC features by taking the mean across the frames (axis=1)\n",
    "    mean_mfcc_features = np.mean(features, axis=1)\n",
    "    \n",
    "    # Create a DataFrame from the mean MFCC features and labels\n",
    "    df = pd.DataFrame(mean_mfcc_features, columns=[f'MFCC_{i+1}' for i in range(mean_mfcc_features.shape[1])])\n",
    "    df['label'] = labels\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', cbar=True, vmin=-1, vmax=1)\n",
    "    plt.title('Correlation Heatmap of Mean MFCC Features and Labels')\n",
    "    plt.xlabel('MFCC Features and Label')\n",
    "    plt.ylabel('MFCC Features and Label')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming the features and labels are already defined in your previous code\n",
    "plot_mfcc_label_correlation(features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3bef2f-e850-4710-bd44-e9b69b7d0db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: wav files\\A,Gokul,p95,m,sitting.wav\n",
      "wav files\\A,Gokul,p95,m,sitting.wav, segment:1, label:95\n",
      "wav files\\A,Gokul,p95,m,sitting.wav, segment:2, label:95\n",
      "Processing file: wav files\\A,kundan,p126,m,cycling.wav\n",
      "wav files\\A,kundan,p126,m,cycling.wav, segment:1, label:126\n",
      "wav files\\A,kundan,p126,m,cycling.wav, segment:2, label:126\n",
      "Processing file: wav files\\A,lala,p108,m,basket ball.wav\n",
      "wav files\\A,lala,p108,m,basket ball.wav, segment:1, label:108\n",
      "wav files\\A,lala,p108,m,basket ball.wav, segment:2, label:108\n",
      "Processing file: wav files\\A,Vishwanath,p100,m,sitting.wav\n",
      "wav files\\A,Vishwanath,p100,m,sitting.wav, segment:1, label:100\n",
      "wav files\\A,Vishwanath,p100,m,sitting.wav, segment:2, label:100\n",
      "Processing file: wav files\\a103.wav\n",
      "wav files\\a103.wav, segment:1, label:103\n",
      "wav files\\a103.wav, segment:2, label:103\n",
      "Processing file: wav files\\a113.wav\n",
      "wav files\\a113.wav, segment:1, label:113\n",
      "wav files\\a113.wav, segment:2, label:113\n",
      "Processing file: wav files\\a88.wav\n",
      "wav files\\a88.wav, segment:1, label:88\n",
      "wav files\\a88.wav, segment:2, label:88\n",
      "Processing file: wav files\\a99.wav\n",
      "wav files\\a99.wav, segment:1, label:99\n",
      "wav files\\a99.wav, segment:2, label:99\n",
      "Processing file: wav files\\E,Saurav,p65,m,sitting.wav\n",
      "wav files\\E,Saurav,p65,m,sitting.wav, segment:1, label:65\n",
      "wav files\\E,Saurav,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: wav files\\E,Shaurya,p118,m,sitting.wav\n",
      "wav files\\E,Shaurya,p118,m,sitting.wav, segment:1, label:118\n",
      "wav files\\E,Shaurya,p118,m,sitting.wav, segment:2, label:118\n",
      "Processing file: wav files\\E,vhairav,p144,m,playing.wav\n",
      "wav files\\E,vhairav,p144,m,playing.wav, segment:1, label:144\n",
      "wav files\\E,vhairav,p144,m,playing.wav, segment:2, label:144\n",
      "Processing file: wav files\\I,Kishlay,p85,m,sitting.wav\n",
      "wav files\\I,Kishlay,p85,m,sitting.wav, segment:1, label:85\n",
      "wav files\\I,Kishlay,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: wav files\\I,Sagar,p65,m,sitting.wav\n",
      "wav files\\I,Sagar,p65,m,sitting.wav, segment:1, label:65\n",
      "wav files\\I,Sagar,p65,m,sitting.wav, segment:2, label:65\n",
      "Processing file: wav files\\I,Sanjay,p144,m,running.wav\n",
      "wav files\\I,Sanjay,p144,m,running.wav, segment:1, label:144\n",
      "wav files\\I,Sanjay,p144,m,running.wav, segment:2, label:144\n",
      "Processing file: wav files\\m132.wav\n",
      "wav files\\m132.wav, segment:1, label:132\n",
      "wav files\\m132.wav, segment:2, label:132\n",
      "Processing file: wav files\\m77.wav\n",
      "wav files\\m77.wav, segment:1, label:77\n",
      "wav files\\m77.wav, segment:2, label:77\n",
      "Processing file: wav files\\m79.wav\n",
      "wav files\\m79.wav, segment:1, label:79\n",
      "wav files\\m79.wav, segment:2, label:79\n",
      "Processing file: wav files\\m88.wav\n",
      "wav files\\m88.wav, segment:1, label:88\n",
      "wav files\\m88.wav, segment:2, label:88\n",
      "Processing file: wav files\\O,Abhimanyu,p75,m,sitting.wav\n",
      "wav files\\O,Abhimanyu,p75,m,sitting.wav, segment:1, label:75\n",
      "wav files\\O,Abhimanyu,p75,m,sitting.wav, segment:2, label:75\n",
      "Processing file: wav files\\O,Ayush,p84,m,sitting.wav\n",
      "wav files\\O,Ayush,p84,m,sitting.wav, segment:1, label:84\n",
      "wav files\\O,Ayush,p84,m,sitting.wav, segment:2, label:84\n",
      "Processing file: wav files\\O,Kitasha,p120,m,playing.wav\n",
      "wav files\\O,Kitasha,p120,m,playing.wav, segment:1, label:120\n",
      "wav files\\O,Kitasha,p120,m,playing.wav, segment:2, label:120\n",
      "Processing file: wav files\\U,Anil,p85,m,sitting.wav\n",
      "wav files\\U,Anil,p85,m,sitting.wav, segment:1, label:85\n",
      "wav files\\U,Anil,p85,m,sitting.wav, segment:2, label:85\n",
      "Processing file: wav files\\U,Anjana,p74,m,sitting.wav\n",
      "wav files\\U,Anjana,p74,m,sitting.wav, segment:1, label:74\n",
      "wav files\\U,Anjana,p74,m,sitting.wav, segment:2, label:74\n",
      "Processing file: wav files\\U,Gayatri,p122,m,playing.wav\n",
      "wav files\\U,Gayatri,p122,m,playing.wav, segment:1, label:122\n",
      "wav files\\U,Gayatri,p122,m,playing.wav, segment:2, label:122\n",
      "Processing file: wav files\\U,Rubika,p86,m,walking.wav\n",
      "wav files\\U,Rubika,p86,m,walking.wav, segment:1, label:86\n",
      "wav files\\U,Rubika,p86,m,walking.wav, segment:2, label:86\n",
      "Processing file: wav files\\v100.wav\n",
      "wav files\\v100.wav, segment:1, label:100\n",
      "wav files\\v100.wav, segment:2, label:100\n",
      "Processing file: wav files\\v67.wav\n",
      "wav files\\v67.wav, segment:1, label:67\n",
      "wav files\\v67.wav, segment:2, label:67\n",
      "Processing file: wav files\\v68.wav\n",
      "wav files\\v68.wav, segment:1, label:68\n",
      "wav files\\v68.wav, segment:2, label:68\n",
      "Processing file: wav files\\v72.wav\n",
      "wav files\\v72.wav, segment:1, label:72\n",
      "wav files\\v72.wav, segment:2, label:72\n",
      "Processing file: wav files\\v73.wav\n",
      "wav files\\v73.wav, segment:1, label:73\n",
      "wav files\\v73.wav, segment:2, label:73\n",
      "Processing file: wav files\\v80.wav\n",
      "wav files\\v80.wav, segment:1, label:80\n",
      "wav files\\v80.wav, segment:2, label:80\n",
      "Processing file: wav files\\y105.wav\n",
      "wav files\\y105.wav, segment:1, label:105\n",
      "wav files\\y105.wav, segment:2, label:105\n",
      "Processing file: wav files\\y90.wav\n",
      "wav files\\y90.wav, segment:1, label:90\n",
      "wav files\\y90.wav, segment:2, label:90\n",
      "Processing file: wav files\\y94.wav\n",
      "wav files\\y94.wav, segment:1, label:94\n",
      "wav files\\y94.wav, segment:2, label:94\n",
      "Processing file: wav files\\y95.wav\n",
      "wav files\\y95.wav, segment:1, label:95\n",
      "wav files\\y95.wav, segment:2, label:95\n",
      "Extracted features shape: (70, 300, 13)\n",
      "Labels shape: (70,)\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 329ms/step - loss: 34316.8242 - mean_absolute_error: 179.6160 - val_loss: 689.8640 - val_mean_absolute_error: 22.8386\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 921.6965 - mean_absolute_error: 22.7423 - val_loss: 1029.3561 - val_mean_absolute_error: 23.1053\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1264.0730 - mean_absolute_error: 30.0864 - val_loss: 3804.8672 - val_mean_absolute_error: 57.7608\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2008.6338 - mean_absolute_error: 39.5868 - val_loss: 2143.0500 - val_mean_absolute_error: 40.0980\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 2978.2627 - mean_absolute_error: 50.6193 - val_loss: 1823.1547 - val_mean_absolute_error: 36.4004\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1377.5033 - mean_absolute_error: 28.5872 - val_loss: 958.5244 - val_mean_absolute_error: 23.5781\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 649.2565 - mean_absolute_error: 19.0434 - val_loss: 1533.4066 - val_mean_absolute_error: 31.5162\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1842.2863 - mean_absolute_error: 37.9983 - val_loss: 3913.1853 - val_mean_absolute_error: 57.6865\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1867.5466 - mean_absolute_error: 40.8259 - val_loss: 691.3143 - val_mean_absolute_error: 22.4727\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 587.4536 - mean_absolute_error: 20.0183 - val_loss: 935.9583 - val_mean_absolute_error: 25.8530\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 965.0389 - mean_absolute_error: 27.2415 - val_loss: 3288.0603 - val_mean_absolute_error: 52.6086\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1317.6364 - mean_absolute_error: 33.5674 - val_loss: 554.0576 - val_mean_absolute_error: 20.6429\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 554.4070 - mean_absolute_error: 19.7330 - val_loss: 507.8220 - val_mean_absolute_error: 20.2740\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 387.6328 - mean_absolute_error: 16.6218 - val_loss: 1608.5026 - val_mean_absolute_error: 35.1083\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 463.4547 - mean_absolute_error: 18.8251 - val_loss: 527.3455 - val_mean_absolute_error: 20.0089\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 522.0217 - mean_absolute_error: 20.0094 - val_loss: 923.2812 - val_mean_absolute_error: 24.6293\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 301.0489 - mean_absolute_error: 14.1774 - val_loss: 817.5136 - val_mean_absolute_error: 23.0290\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 206.3441 - mean_absolute_error: 11.2387 - val_loss: 398.8987 - val_mean_absolute_error: 17.7519\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 271.5168 - mean_absolute_error: 13.8260 - val_loss: 1181.8584 - val_mean_absolute_error: 29.8251\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 343.4666 - mean_absolute_error: 16.1821 - val_loss: 385.6694 - val_mean_absolute_error: 16.3570\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 253.7383 - mean_absolute_error: 12.6887 - val_loss: 396.9855 - val_mean_absolute_error: 15.9007\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 126.2127 - mean_absolute_error: 8.9078 - val_loss: 1127.9988 - val_mean_absolute_error: 29.7992\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 247.3322 - mean_absolute_error: 13.4635 - val_loss: 336.5896 - val_mean_absolute_error: 15.3687\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 426.2563 - mean_absolute_error: 19.1408 - val_loss: 510.0956 - val_mean_absolute_error: 18.0348\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 95.9587 - mean_absolute_error: 8.0459 - val_loss: 765.1584 - val_mean_absolute_error: 23.0852\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 167.3641 - mean_absolute_error: 11.3196 - val_loss: 283.9935 - val_mean_absolute_error: 15.1954\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 132.8138 - mean_absolute_error: 9.3613 - val_loss: 829.0288 - val_mean_absolute_error: 24.4609\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 189.0125 - mean_absolute_error: 12.4064 - val_loss: 367.1555 - val_mean_absolute_error: 15.7339\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 45.6153 - mean_absolute_error: 5.2785 - val_loss: 263.3416 - val_mean_absolute_error: 14.1650\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 82.1176 - mean_absolute_error: 7.3626 - val_loss: 682.9983 - val_mean_absolute_error: 22.0187\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 104.9652 - mean_absolute_error: 8.6421 - val_loss: 254.3937 - val_mean_absolute_error: 13.8734\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 70.3349 - mean_absolute_error: 6.7753 - val_loss: 427.2579 - val_mean_absolute_error: 16.5889\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 37.1632 - mean_absolute_error: 4.6665 - val_loss: 315.1939 - val_mean_absolute_error: 15.2201\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 32.3848 - mean_absolute_error: 4.6871 - val_loss: 275.8273 - val_mean_absolute_error: 14.9891\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 42.6335 - mean_absolute_error: 5.2425 - val_loss: 539.0446 - val_mean_absolute_error: 19.0111\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 68.5834 - mean_absolute_error: 6.9226 - val_loss: 227.2631 - val_mean_absolute_error: 13.7954\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 71.3336 - mean_absolute_error: 6.7604 - val_loss: 452.7858 - val_mean_absolute_error: 17.1377\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 44.5699 - mean_absolute_error: 5.4796 - val_loss: 276.1751 - val_mean_absolute_error: 13.4920\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 22.2848 - mean_absolute_error: 3.3894 - val_loss: 297.1199 - val_mean_absolute_error: 13.9408\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 17.2265 - mean_absolute_error: 3.0362 - val_loss: 351.5030 - val_mean_absolute_error: 15.0366\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 11.7960 - mean_absolute_error: 2.7160 - val_loss: 256.4492 - val_mean_absolute_error: 13.8791\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 24.4138 - mean_absolute_error: 3.9007 - val_loss: 440.4589 - val_mean_absolute_error: 16.6495\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 24.8050 - mean_absolute_error: 4.3472 - val_loss: 275.3936 - val_mean_absolute_error: 14.5215\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 24.1497 - mean_absolute_error: 3.9312 - val_loss: 386.6704 - val_mean_absolute_error: 15.8862\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 12.7803 - mean_absolute_error: 2.9465 - val_loss: 334.7185 - val_mean_absolute_error: 14.9000\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 7.0303 - mean_absolute_error: 2.0753 - val_loss: 332.1302 - val_mean_absolute_error: 14.7707\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 6.5497 - mean_absolute_error: 1.9158 - val_loss: 309.4230 - val_mean_absolute_error: 14.2989\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 4.7797 - mean_absolute_error: 1.7300 - val_loss: 299.2267 - val_mean_absolute_error: 14.0905\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4.0042 - mean_absolute_error: 1.6274 - val_loss: 369.0180 - val_mean_absolute_error: 15.4142\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 9.6494 - mean_absolute_error: 2.5709 - val_loss: 286.1948 - val_mean_absolute_error: 14.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 298.8050 - mean_absolute_error: 14.6758\n",
      "Test Mean Absolute Error: 14.675779342651367\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FA6884B880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FA6884B880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Accuracy Percentage: 14.29%\n",
      "Actual: 85, Predicted: 56.4177360534668\n",
      "Actual: 95, Predicted: 74.56463623046875\n",
      "Actual: 86, Predicted: 94.73439025878906\n",
      "Actual: 108, Predicted: 83.40609741210938\n",
      "Actual: 68, Predicted: 96.97932434082031\n",
      "Actual: 118, Predicted: 91.18647766113281\n",
      "Actual: 113, Predicted: 95.68280029296875\n",
      "Actual: 79, Predicted: 84.36100769042969\n",
      "Actual: 74, Predicted: 62.00930404663086\n",
      "Actual: 88, Predicted: 97.23451232910156\n",
      "Actual: 77, Predicted: 80.73393249511719\n",
      "Actual: 103, Predicted: 110.24952697753906\n",
      "Actual: 94, Predicted: 102.12939453125\n",
      "Actual: 108, Predicted: 112.30587005615234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "num_segments = 2  # Number of segments to divide each audio file\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "\n",
    "# Directory containing audio files\n",
    "input_dir = 'wav files'  # Replace with your directory containing .wav files\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Function to extract MFCC features from an audio file segment\n",
    "def extract_mfcc_segment(signal, sample_rate, start, finish):\n",
    "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfcc.T\n",
    "\n",
    "# Function to extract oximeter reading from file name\n",
    "def extract_oximeter_reading(file_name):\n",
    "    oximeter_reading = int(''.join(filter(str.isdigit, file_name)))\n",
    "    return oximeter_reading\n",
    "\n",
    "# Pad or truncate MFCC features to a consistent length\n",
    "def pad_or_truncate(mfcc, max_length):\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "# Process each file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Load audio file\n",
    "        audio, original_fs = sf.read(file_path)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = librosa.to_mono(audio.T)\n",
    "        if original_fs != fs:\n",
    "            audio = librosa.resample(audio, orig_sr=original_fs, target_sr=fs)\n",
    "        \n",
    "        # Calculate segment length and number of MFCC vectors per segment\n",
    "        samples_per_segment = int(len(audio) / num_segments)\n",
    "        num_mfcc_vectors_per_segment = int(np.ceil(samples_per_segment / hop_length))\n",
    "\n",
    "        # Extract MFCC features from each segment\n",
    "        for segment in range(num_segments):\n",
    "            start = samples_per_segment * segment\n",
    "            finish = start + samples_per_segment\n",
    "            \n",
    "            mfcc_features = extract_mfcc_segment(audio, fs, start, finish)\n",
    "            mfcc_features = pad_or_truncate(mfcc_features, max_length)\n",
    "            \n",
    "            # Append the MFCC features of the current segment\n",
    "            features.append(mfcc_features)\n",
    "            # Append the label (oximeter reading) of the current segment\n",
    "            oximeter_reading = extract_oximeter_reading(filename)\n",
    "            labels.append(oximeter_reading)\n",
    "            print(f\"{file_path}, segment:{segment + 1}, label:{oximeter_reading}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(max_length, n_mfcc)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'trained_model.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Load the model (you can load it in a different script or session)\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy percentage\n",
    "tolerance = 5  # Define a tolerance level for the predictions\n",
    "accurate_predictions = np.sum(np.abs(y_pred.flatten() - y_test) <= tolerance)\n",
    "accuracy_percentage = (accurate_predictions / len(y_test)) * 100\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n",
    "\n",
    "# Print the predictions and actual labels\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_pred[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c819b7-9137-4c76-806c-79ecaf18e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 298.8050 - mean_absolute_error: 14.6758\n",
      "Test Mean Absolute Error: 14.675779342651367\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FA604391C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FA604391C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "Accuracy Percentage: 14.29%\n",
      "Actual: 85, Predicted: 56.4177360534668\n",
      "Actual: 95, Predicted: 74.56463623046875\n",
      "Actual: 86, Predicted: 94.73439025878906\n",
      "Actual: 108, Predicted: 83.40609741210938\n",
      "Actual: 68, Predicted: 96.97932434082031\n",
      "Actual: 118, Predicted: 91.18647766113281\n",
      "Actual: 113, Predicted: 95.68280029296875\n",
      "Actual: 79, Predicted: 84.36100769042969\n",
      "Actual: 74, Predicted: 62.00930404663086\n",
      "Actual: 88, Predicted: 97.23451232910156\n",
      "Actual: 77, Predicted: 80.73393249511719\n",
      "Actual: 103, Predicted: 110.24952697753906\n",
      "Actual: 94, Predicted: 102.12939453125\n",
      "Actual: 108, Predicted: 112.30587005615234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import sounddevice as sd\n",
    "\n",
    "# Parameters\n",
    "fs = 44100  # Target sampling rate\n",
    "n_mfcc = 13  # Number of MFCC features\n",
    "n_fft = 2048  # Interval to apply FFT\n",
    "hop_length = 512  # Sliding window for FFT\n",
    "max_length = 300  # Maximum length of MFCC features (number of frames)\n",
    "record_duration = 6  # Duration of the recording in seconds\n",
    "\n",
    "# Load the trained model\n",
    "model_save_path = 'trained_model.h5'\n",
    "model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Record audio for the specified duration\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(record_duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished\")\n",
    "\n",
    "# Convert to mono if needed\n",
    "if audio.ndim > 1:\n",
    "    audio = librosa.to_mono(audio.T)\n",
    "\n",
    "# Extract MFCC features from the recorded audio\n",
    "def extract_mfcc_from_audio(audio, sample_rate, n_mfcc, n_fft, hop_length, max_length):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc = mfcc.T\n",
    "    # Pad or truncate MFCC features to a consistent length\n",
    "    if len(mfcc) < max_length:\n",
    "        pad_width = max_length - len(mfcc)\n",
    "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:max_length]\n",
    "    return mfcc\n",
    "\n",
    "mfcc_features = extract_mfcc_from_audio(audio.flatten(), fs, n_mfcc, n_fft, hop_length, max_length)\n",
    "mfcc_features = np.expand_dims(mfcc_features, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict the output using the model\n",
    "prediction = model.predict(mfcc_features)\n",
    "print(f\"Predicted Value: {prediction[0][0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceef3d8-5ffd-4d24-855e-fc9e54b3a10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
